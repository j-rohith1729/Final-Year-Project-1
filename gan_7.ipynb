{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv('kaggle_real_data.csv')\n",
    "df=pd.get_dummies(df,['Airline','Source','Destination','Journey_Day_of_Week'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Duration</th>\n",
       "      <th>Price</th>\n",
       "      <th>Journey_Date</th>\n",
       "      <th>Journey_Month</th>\n",
       "      <th>Journey_Year</th>\n",
       "      <th>Stops</th>\n",
       "      <th>Departure_Minutes</th>\n",
       "      <th>Arrival_Minutes</th>\n",
       "      <th>Reaching_Next_Day</th>\n",
       "      <th>Airline_Air Asia</th>\n",
       "      <th>...</th>\n",
       "      <th>Destination_Hyderabad</th>\n",
       "      <th>Destination_Kolkata</th>\n",
       "      <th>Destination_New Delhi</th>\n",
       "      <th>Journey_Day_of_Week_Friday</th>\n",
       "      <th>Journey_Day_of_Week_Monday</th>\n",
       "      <th>Journey_Day_of_Week_Saturday</th>\n",
       "      <th>Journey_Day_of_Week_Sunday</th>\n",
       "      <th>Journey_Day_of_Week_Thursday</th>\n",
       "      <th>Journey_Day_of_Week_Tuesday</th>\n",
       "      <th>Journey_Day_of_Week_Wednesday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>170</td>\n",
       "      <td>3897</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>2019</td>\n",
       "      <td>0</td>\n",
       "      <td>1340</td>\n",
       "      <td>70</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>445</td>\n",
       "      <td>7662</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "      <td>350</td>\n",
       "      <td>795</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1140</td>\n",
       "      <td>13882</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "      <td>565</td>\n",
       "      <td>265</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Duration  Price  Journey_Date  Journey_Month  Journey_Year  Stops  \\\n",
       "0       170   3897            24              3          2019      0   \n",
       "1       445   7662             1              5          2019      2   \n",
       "2      1140  13882             9              6          2019      2   \n",
       "\n",
       "   Departure_Minutes  Arrival_Minutes  Reaching_Next_Day  Airline_Air Asia  \\\n",
       "0               1340               70               True             False   \n",
       "1                350              795              False             False   \n",
       "2                565              265               True             False   \n",
       "\n",
       "   ...  Destination_Hyderabad  Destination_Kolkata  Destination_New Delhi  \\\n",
       "0  ...                  False                False                   True   \n",
       "1  ...                  False                False                  False   \n",
       "2  ...                  False                False                  False   \n",
       "\n",
       "   Journey_Day_of_Week_Friday  Journey_Day_of_Week_Monday  \\\n",
       "0                       False                       False   \n",
       "1                       False                       False   \n",
       "2                       False                       False   \n",
       "\n",
       "   Journey_Day_of_Week_Saturday  Journey_Day_of_Week_Sunday  \\\n",
       "0                         False                        True   \n",
       "1                         False                       False   \n",
       "2                         False                        True   \n",
       "\n",
       "   Journey_Day_of_Week_Thursday  Journey_Day_of_Week_Tuesday  \\\n",
       "0                         False                        False   \n",
       "1                         False                        False   \n",
       "2                         False                        False   \n",
       "\n",
       "   Journey_Day_of_Week_Wednesday  \n",
       "0                          False  \n",
       "1                           True  \n",
       "2                          False  \n",
       "\n",
       "[3 rows x 39 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 00:05:10.695506: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-11 00:05:10.807935: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-11 00:05:13.949734: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.get_logger().setLevel(logging.ERROR)\n",
    "\n",
    "class GAN:\n",
    "    def __init__(self, data, latent_dim=64, batch_size=32, n_epochs=200):\n",
    "        self.data = data\n",
    "        self.latent_dim = latent_dim\n",
    "        self.batch_size = batch_size\n",
    "        self.n_epochs = n_epochs\n",
    "\n",
    "    # Generate random noise in the latent space\n",
    "    def _noise(self, batch_size):\n",
    "        return np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
    "\n",
    "    def _generator(self):\n",
    "        model = tf.keras.Sequential(name=\"Generator_model\")\n",
    "        model.add(tf.keras.layers.Dense(128, activation='relu', kernel_initializer='he_uniform', input_dim=self.latent_dim))\n",
    "        model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "        model.add(tf.keras.layers.Dense(self.data.shape[1], activation='linear'))  # Output layer has the same size as input data\n",
    "        return model\n",
    "\n",
    "    def _discriminator(self):\n",
    "        model = tf.keras.Sequential(name=\"Discriminator_model\")\n",
    "        model.add(tf.keras.layers.Dense(256, activation='relu', kernel_initializer='he_uniform', input_dim=self.data.shape[1]))\n",
    "        model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "        model.add(tf.keras.layers.Dense(1, activation='sigmoid'))  # Binary classification (real or fake)\n",
    "        model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        return model\n",
    "\n",
    "    # Define the combined generator and discriminator model, for updating the generator\n",
    "    def _GAN(self, generator, discriminator):\n",
    "        discriminator.trainable = False\n",
    "        generator.trainable = True\n",
    "        model = tf.keras.Sequential(name=\"GAN\")\n",
    "        model.add(generator)\n",
    "        model.add(discriminator)\n",
    "        model.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "        return model\n",
    "\n",
    "    # Train the generator and discriminator\n",
    "    def train(self):\n",
    "        generator = self._generator()\n",
    "        discriminator = self._discriminator()\n",
    "        gan = self._GAN(generator, discriminator)\n",
    "\n",
    "        # Training loop\n",
    "        for epoch in range(self.n_epochs):\n",
    "            # Select a random batch of real data\n",
    "            idx = np.random.randint(0, self.data.shape[0], self.batch_size)\n",
    "            real_data = self.data[idx]\n",
    "\n",
    "            # Generate a batch of fake data\n",
    "            noise = self._noise(self.batch_size)\n",
    "            fake_data = generator.predict(noise)\n",
    "\n",
    "            # Train the discriminator on real and fake data\n",
    "            d_loss_real = discriminator.train_on_batch(real_data, np.ones((self.batch_size, 1)))\n",
    "            d_loss_fake = discriminator.train_on_batch(fake_data, np.zeros((self.batch_size, 1)))\n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "            # Train the generator (wants discriminator to label generated samples as real)\n",
    "            noise = self._noise(self.batch_size)\n",
    "            g_loss = gan.train_on_batch(noise, np.ones((self.batch_size, 1)))\n",
    "\n",
    "            # Print progress\n",
    "            if (epoch + 1) % 100 == 0:\n",
    "                print(f\"Epoch: {epoch + 1}/{self.n_epochs}, D Loss: {d_loss[0]:.4f}, G Loss: {g_loss:.4f}\")\n",
    "\n",
    "        return generator\n",
    "\n",
    "    # Generate synthetic data\n",
    "    def generate_synthetic_data(self, generator, num_samples=1000):\n",
    "        noise = self._noise(num_samples)\n",
    "        synthetic_data = generator.predict(noise)\n",
    "        synthetic_df = pd.DataFrame(synthetic_data, columns=self.data.columns)\n",
    "        return synthetic_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "data = scaler.fit_transform(df)\n",
    "gan = GAN(data, latent_dim=64, batch_size=32, n_epochs=2000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 00:05:18.430019: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-11 00:05:18.430550: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2251] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "WARNING:absl:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "#generator = gan.train()\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the saved model\n",
    "generator = load_model('generator_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Function to generate synthetic data using a trained generator and restore original column names\n",
    "def generate_synthetic_data(generator, latent_dim, original_columns, num_samples=1000):\n",
    "    # Generate random noise to feed into the generator\n",
    "    noise = np.random.normal(0, 1, (num_samples, latent_dim))\n",
    "    \n",
    "    # Use the generator to create synthetic data\n",
    "    synthetic_data = generator.predict(noise)\n",
    "    \n",
    "    # Convert the generated data to a pandas DataFrame\n",
    "    synthetic_df = pd.DataFrame(synthetic_data, columns=original_columns)\n",
    "    \n",
    "    return synthetic_df\n",
    "\n",
    "# Example usage\n",
    "# Assuming 'generator' is your trained generator model, 'latent_dim' is the size of the noise vector\n",
    "# and 'original_columns' is a list of your original column names\n",
    "\n",
    "# List of original columns from your dataset\n",
    "original_columns =df.columns\n",
    "\n",
    "num_samples = 2000  # Number of synthetic samples you want to generate\n",
    "synthetic_data = generate_synthetic_data(generator, latent_dim=64, original_columns=original_columns, num_samples=num_samples)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverted_data = scaler.inverse_transform(synthetic_data)\n",
    "\n",
    "# Convert it back to a DataFrame with original column names\n",
    "reverted_df = pd.DataFrame(reverted_data, columns=df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_array = scaler.fit_transform(df)\n",
    "\n",
    "# Convert the scaled array back to a DataFrame, keeping the same columns\n",
    "df1 = pd.DataFrame(scaled_array, columns=df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Duration', 'Price', 'Journey_Date', 'Journey_Month', 'Journey_Year',\n",
       "       'Stops', 'Departure_Minutes', 'Arrival_Minutes', 'Reaching_Next_Day',\n",
       "       'Airline_Air Asia', 'Airline_Air India', 'Airline_GoAir',\n",
       "       'Airline_IndiGo', 'Airline_Jet Airways', 'Airline_Jet Airways Business',\n",
       "       'Airline_Multiple carriers',\n",
       "       'Airline_Multiple carriers Premium economy', 'Airline_SpiceJet',\n",
       "       'Airline_Trujet', 'Airline_Vistara', 'Airline_Vistara Premium economy',\n",
       "       'Source_Banglore', 'Source_Chennai', 'Source_Delhi', 'Source_Kolkata',\n",
       "       'Source_Mumbai', 'Destination_Banglore', 'Destination_Cochin',\n",
       "       'Destination_Delhi', 'Destination_Hyderabad', 'Destination_Kolkata',\n",
       "       'Destination_New Delhi', 'Journey_Day_of_Week_Friday',\n",
       "       'Journey_Day_of_Week_Monday', 'Journey_Day_of_Week_Saturday',\n",
       "       'Journey_Day_of_Week_Sunday', 'Journey_Day_of_Week_Thursday',\n",
       "       'Journey_Day_of_Week_Tuesday', 'Journey_Day_of_Week_Wednesday'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reverted_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Duration</th>\n",
       "      <th>Price</th>\n",
       "      <th>Journey_Date</th>\n",
       "      <th>Journey_Month</th>\n",
       "      <th>Journey_Year</th>\n",
       "      <th>Stops</th>\n",
       "      <th>Departure_Minutes</th>\n",
       "      <th>Arrival_Minutes</th>\n",
       "      <th>Reaching_Next_Day</th>\n",
       "      <th>Airline_Air Asia</th>\n",
       "      <th>...</th>\n",
       "      <th>Destination_Hyderabad</th>\n",
       "      <th>Destination_Kolkata</th>\n",
       "      <th>Destination_New Delhi</th>\n",
       "      <th>Journey_Day_of_Week_Friday</th>\n",
       "      <th>Journey_Day_of_Week_Monday</th>\n",
       "      <th>Journey_Day_of_Week_Saturday</th>\n",
       "      <th>Journey_Day_of_Week_Sunday</th>\n",
       "      <th>Journey_Day_of_Week_Thursday</th>\n",
       "      <th>Journey_Day_of_Week_Tuesday</th>\n",
       "      <th>Journey_Day_of_Week_Wednesday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>999.0</td>\n",
       "      <td>3942.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>696.0</td>\n",
       "      <td>664.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>775.0</td>\n",
       "      <td>5852.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>656.0</td>\n",
       "      <td>846.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>845.0</td>\n",
       "      <td>5405.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>453.0</td>\n",
       "      <td>688.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>734.0</td>\n",
       "      <td>4905.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>486.0</td>\n",
       "      <td>829.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>532.0</td>\n",
       "      <td>3273.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>511.0</td>\n",
       "      <td>1091.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Duration   Price  Journey_Date  Journey_Month  Journey_Year  Stops  \\\n",
       "0     999.0  3942.0           7.0            4.0        2019.0    1.0   \n",
       "1     775.0  5852.0          12.0            4.0        2019.0    1.0   \n",
       "2     845.0  5405.0          16.0            4.0        2019.0    2.0   \n",
       "3     734.0  4905.0          10.0            4.0        2019.0    1.0   \n",
       "4     532.0  3273.0          12.0            4.0        2019.0    2.0   \n",
       "\n",
       "   Departure_Minutes  Arrival_Minutes Reaching_Next_Day Airline_Air Asia  ...  \\\n",
       "0              696.0            664.0              True            False  ...   \n",
       "1              656.0            846.0             False            False  ...   \n",
       "2              453.0            688.0             False            False  ...   \n",
       "3              486.0            829.0             False            False  ...   \n",
       "4              511.0           1091.0             False            False  ...   \n",
       "\n",
       "  Destination_Hyderabad Destination_Kolkata Destination_New Delhi  \\\n",
       "0                 False               False                 False   \n",
       "1                 False               False                 False   \n",
       "2                 False               False                 False   \n",
       "3                 False               False                 False   \n",
       "4                  True               False                 False   \n",
       "\n",
       "  Journey_Day_of_Week_Friday Journey_Day_of_Week_Monday  \\\n",
       "0                      False                      False   \n",
       "1                      False                      False   \n",
       "2                      False                       True   \n",
       "3                      False                       True   \n",
       "4                      False                       True   \n",
       "\n",
       "  Journey_Day_of_Week_Saturday Journey_Day_of_Week_Sunday  \\\n",
       "0                         True                      False   \n",
       "1                        False                      False   \n",
       "2                        False                      False   \n",
       "3                        False                      False   \n",
       "4                        False                      False   \n",
       "\n",
       "  Journey_Day_of_Week_Thursday Journey_Day_of_Week_Tuesday  \\\n",
       "0                        False                       False   \n",
       "1                         True                       False   \n",
       "2                        False                       False   \n",
       "3                        False                       False   \n",
       "4                        False                       False   \n",
       "\n",
       "  Journey_Day_of_Week_Wednesday  \n",
       "0                         False  \n",
       "1                         False  \n",
       "2                         False  \n",
       "3                         False  \n",
       "4                         False  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reverted_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range of the column(reverted_df): 7283.674\n",
      "Range of the column(reverted_df): 95.08223\n",
      "Range of the column(df): 1435\n",
      "Range of the column(df): 5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(\"Range of the column(reverted_df):\", reverted_df['Arrival_Minutes'].max())\n",
    "print(\"Range of the column(reverted_df):\", reverted_df['Arrival_Minutes'].min())\n",
    "print(\"Range of the column(df):\", df['Arrival_Minutes'].max())\n",
    "print(\"Range of the column(df):\", df['Arrival_Minutes'].min())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_df = df['Arrival_Minutes'].min()\n",
    "max_df = df['Arrival_Minutes'].max()\n",
    "\n",
    "min_reverted = reverted_df['Arrival_Minutes'].min()\n",
    "max_reverted = reverted_df['Arrival_Minutes'].max()\n",
    "\n",
    "scaled = ((reverted_df['Arrival_Minutes'] - min_reverted) / (max_reverted - min_reverted)) * (max_df - min_df) + min_df\n",
    "\n",
    "# Step 3: Update the 'Price' column in reverted_df with the scaled values\n",
    "reverted_df['Arrival_Minutes'] = scaled\n",
    "reverted_df['Arrival_Minutes'] = reverted_df['Arrival_Minutes'].round()\n",
    "\n",
    "# If you want to convert the rounded values to integers (optional):\n",
    "reverted_df['Arrival_Minutes'] = reverted_df['Arrival_Minutes'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame to a CSV file\n",
    "reverted_df.to_csv('real+generated_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
